{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Installation\n",
    "- Download pre-trained Models\n",
    "- Tokenization\n",
    "- Lemmatization\n",
    "- Token Extracting / Removing / Transforming\n",
    "- Sentence Segmentation\n",
    "- Part of Speech Tagging\n",
    "- Named Entity Recognition\n",
    "- Dependency Parsing\n",
    "- Word Vectors\n",
    "- Sentence Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- spaCy is compatible with 64-bit CPython 2.7 / 3.5+ \n",
    "- Runs on Unix/Linux, macOS/OS X and Windows\n",
    "- The latest spaCy releases are available over pip and conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -c conda-forge spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download pre-trained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to download a model is via spaCy‚Äôs download command.  \n",
    "\n",
    "It takes care of finding the best-matching model compatible with your spaCy installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy‚Äôs models can also be installed as Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With external URL\n",
    "# !pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz\n",
    "\n",
    "# With local file\n",
    "# !pip install /Users/you/en_core_web_sm-2.2.5.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directory structure\n",
    "‚îî‚îÄ‚îÄ en_core_web_md-2.2.0.tar.gz       # downloaded archive\n",
    "    ‚îú‚îÄ‚îÄ meta.json                     # model meta data\n",
    "    ‚îú‚îÄ‚îÄ setup.py                      # setup file for pip installation\n",
    "    ‚îî‚îÄ‚îÄ en_core_web_md                # üì¶ model package\n",
    "        ‚îú‚îÄ‚îÄ __init__.py               # init for pip installation\n",
    "        ‚îú‚îÄ‚îÄ meta.json                 # model meta data\n",
    "        ‚îî‚îÄ‚îÄ en_core_web_md-2.2.0      # model data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"This is a sentence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('This', 'DET'), ('is', 'AUX'), ('a', 'DET'), ('sentence', 'NOUN'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "print([(w.text, w.pos_) for w in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using white space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Rare bird‚Äôs detection highlights promise of ‚Äòenvironmental DNA‚Äô\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rare\n",
      "bird‚Äôs\n",
      "detection\n",
      "highlights\n",
      "promise\n",
      "of\n",
      "‚Äòenvironmental\n",
      "DNA‚Äô\n"
     ]
    }
   ],
   "source": [
    "token_lsit = text.split()\n",
    "for token in token_lsit:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rare\n",
      "bird\n",
      "‚Äôs\n",
      "detection\n",
      "highlights\n",
      "promise\n",
      "of\n",
      "‚Äò\n",
      "environmental\n",
      "DNA\n",
      "‚Äô\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization is the process of reducing inflected forms of a word while still ensuring that the reduced form belongs to the language (converts words in the second or third forms to their first form variants). This reduced form or root word is called a lemma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"look, looks, looked and looking\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token:look -> lemma:look\n",
      "token:, -> lemma:,\n",
      "token:looks -> lemma:look\n",
      "token:, -> lemma:,\n",
      "token:looked -> lemma:look\n",
      "token:and -> lemma:and\n",
      "token:looking -> lemma:looking\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(\"token:{} -> lemma:{}\".format(token.text,token.lemma_ ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Syracuse University has never been bound by convention or the status quo.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token:Syracuse -> lemma:Syracuse\n",
      "token:University -> lemma:University\n",
      "token:has -> lemma:have\n",
      "token:never -> lemma:never\n",
      "token:been -> lemma:be\n",
      "token:bound -> lemma:bind\n",
      "token:by -> lemma:by\n",
      "token:convention -> lemma:convention\n",
      "token:or -> lemma:or\n",
      "token:the -> lemma:the\n",
      "token:status -> lemma:status\n",
      "token:quo -> lemma:quo\n",
      "token:. -> lemma:.\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(\"token:{} -> lemma:{}\".format(token.text,token.lemma_ ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''Since 1870, Syracuse University has upheld the idea that ‚Äúbrains and heart shall have a fair chance‚Äù at achieving a University degree. We were pioneers in recognizing women‚Äôs achievements, the academic validity of the fine arts, the emergence of information studies and the importance of educational opportunities that serve veterans. Our founding values are embedded in 150 years of educational innovation, expansion, discovery and change.\n",
    "\n",
    "See a timeline of events in Syracuse University's 150 years of history.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "words =  [token.text for token in doc if token.is_punct != True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counter = Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('of', 6), ('the', 5), ('University', 3), ('and', 3), ('a', 3)]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counter.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counter[\"Syracuse\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token Extracting / Removing / Transforming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|Attribute Name\t|Type|Description                                                                    |\n",
    "|:--------------------:|:---------:|:------------------------------------------------------------------------------------------------------------------------------------:|\n",
    "| lemma              | int     | Base form of the token, with no inflectional suffixes.                                                                             |\n",
    "| lemma_             | unicode | Base form of the token, with no inflectional suffixes.                                                                             |\n",
    "| norm               | int     | The token‚Äôs norm, i.e. a normalized form of the token text. Usually set in the language‚Äôs tokenizer exceptions or norm exceptions. |\n",
    "| norm_              | unicode | The token‚Äôs norm, i.e. a normalized form of the token text. Usually set in the language‚Äôs tokenizer exceptions or norm exceptions. |\n",
    "| lower              | int     | Lowercase form of the token.                                                                                                       |\n",
    "| lower_             | unicode | Lowercase form of the token text. Equivalent to Token.text.lower().                                                                |\n",
    "| shape              | int     | Transform of the tokens‚Äôs string, to show orthographic features. For example, ‚ÄúXxxx‚Äù or ‚Äúdd‚Äù.                                      |\n",
    "| shape_             | unicode | Transform of the tokens‚Äôs string, to show orthographic features. For example, ‚ÄúXxxx‚Äù or ‚Äúdd‚Äù.                                      |\n",
    "| prefix             | int     | Hash value of a length-N substring from the start of the token. Defaults to N=1.                                                   |\n",
    "| prefix_            | unicode | A length-N substring from the start of the token. Defaults to N=1.                                                                 |\n",
    "| suffix             | int     | Hash value of a length-N substring from the end of the token. Defaults to N=3.                                                     |\n",
    "| suffix_            | unicode | Length-N substring from the end of the token. Defaults to N=3.                                                                     |\n",
    "| is_alpha           | bool    | Does the token consist of alphabetic characters? Equivalent to token.text.isalpha().                                               |\n",
    "| is_ascii           | bool    | Does the token consist of ASCII characters? Equivalent to all(ord(c) < 128 for c in token.text).                                   |\n",
    "| is_digit           | bool    | Does the token consist of digits? Equivalent to token.text.isdigit().                                                              |\n",
    "| is_lower           | bool    | Is the token in lowercase? Equivalent to token.text.islower().                                                                     |\n",
    "| is_upper           | bool    | Is the token in uppercase? Equivalent to token.text.isupper().                                                                     |\n",
    "| is_title           | bool    | Is the token in titlecase? Equivalent to token.text.istitle().                                                                     |\n",
    "| is_punct           | bool    | Is the token punctuation?                                                                                                          |\n",
    "| is_left_punct      | bool    | Is the token a left punctuation mark, e.g. (?                                                                                      |\n",
    "| is_right_punct     | bool    | Is the token a right punctuation mark, e.g. )?                                                                                     |\n",
    "| is_space           | bool    | Does the token consist of whitespace characters? Equivalent to token.text.isspace().                                               |\n",
    "| is_bracket         | bool    | Is the token a bracket?                                                                                                            |\n",
    "| is_quote           | bool    | Is the token a quotation mark?                                                                                                     |\n",
    "| is_currency V2.0.8 | bool    | Is the token a currency symbol?                                                                                                    |\n",
    "| like_url           | bool    | Does the token resemble a URL?                                                                                                     |\n",
    "| like_num           | bool    | Does the token represent a number? e.g. ‚Äú10.9‚Äù, ‚Äú10‚Äù, ‚Äúten‚Äù, etc.                                                                  |\n",
    "| like_email         | bool    | Does the token resemble an email address?                                                                                          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text='''The future opens wide for those who can master our ever-evolving,\n",
    "data-driven world ‚Äì come learn that mastery from the experts\n",
    "at the Syracuse University iSchool!'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      ",\n",
      "-\n",
      "‚Äì\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "num_list=[]\n",
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    if token.is_punct:\n",
    "        num_list.append(token)\n",
    "for punc in num_list:\n",
    "    print(punc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spacy_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nine',\n",
       " 'really',\n",
       " 'anywhere',\n",
       " 'move',\n",
       " 'sometime',\n",
       " 'give',\n",
       " 'against',\n",
       " 'per',\n",
       " 'whereafter',\n",
       " 'into',\n",
       " 'nobody',\n",
       " 'among',\n",
       " 'ours',\n",
       " 'neither',\n",
       " 'everything',\n",
       " 'third',\n",
       " 'since',\n",
       " 'very',\n",
       " 'other',\n",
       " 'always']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(spacy_stopwords)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"The quick brown fox jumps over the lazy dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_stop_words = [token for token in doc if not token.is_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[quick, brown, fox, jumps, lazy, dog]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"The quick brown fox jumps over the lazy dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowercased = [ token.lower_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowercased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = (\"text\", \"lemma_\",\"is_punct\", \"is_stop\", \"is_alpha\", \"is_space\", \"lower_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [] \n",
    "for t in doc:\n",
    "    row = [t.text, t.lemma_,  t.is_punct,  t.is_stop,  t.is_alpha,  t.is_space,  t.lower_]\n",
    "    rows.append(row)\n",
    "attri_pdf = pd.DataFrame(rows, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma_</th>\n",
       "      <th>is_punct</th>\n",
       "      <th>is_stop</th>\n",
       "      <th>is_alpha</th>\n",
       "      <th>is_space</th>\n",
       "      <th>lower_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quick</td>\n",
       "      <td>quick</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>quick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brown</td>\n",
       "      <td>brown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fox</td>\n",
       "      <td>fox</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>fox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jumps</td>\n",
       "      <td>jump</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>jumps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>over</td>\n",
       "      <td>over</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lazy</td>\n",
       "      <td>lazy</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>lazy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dog</td>\n",
       "      <td>dog</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>dog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text lemma_  is_punct  is_stop  is_alpha  is_space lower_\n",
       "0    The    the     False     True      True     False    the\n",
       "1  quick  quick     False    False      True     False  quick\n",
       "2  brown  brown     False    False      True     False  brown\n",
       "3    fox    fox     False    False      True     False    fox\n",
       "4  jumps   jump     False    False      True     False  jumps\n",
       "5   over   over     False     True      True     False   over\n",
       "6    the    the     False     True      True     False    the\n",
       "7   lazy   lazy     False    False      True     False   lazy\n",
       "8    dog    dog     False    False      True     False    dog"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attri_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''In some cases, eDNA analyses are being used to enforce policy. For example, in 2014, the UK government approved the use of eDNA analysis for detecting the endangered great crested newt in land-use surveys that are required by law.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In some cases, eDNA analyses are being used to enforce policy. For example, in 2014, the UK government approved the use of eDNA analysis for detecting the endangered great crested newt in land-use surveys that are required by law.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_pos=0, end_pos=13, text:In some cases, eDNA analyses are being used to enforce policy.\n",
      "start_pos=13, end_pos=46, text:For example, in 2014, the UK government approved the use of eDNA analysis for detecting the endangered great crested newt in land-use surveys that are required by law.\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print(\"start_pos={}, end_pos={}, text:{}\".format(sent.start, sent.end, sent.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part of Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"The quick brown fox jumps over the lazy dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DT DET determiner\n",
      "quick JJ ADJ adjective\n",
      "brown JJ ADJ adjective\n",
      "fox NN NOUN noun, singular or mass\n",
      "jumps NNS NOUN noun, plural\n",
      "over IN ADP conjunction, subordinating or preposition\n",
      "the DT DET determiner\n",
      "lazy JJ ADJ adjective\n",
      "dog NN NOUN noun, singular or mass\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print (token, token.tag_, token.pos_, spacy.explain(token.tag_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| TAG | ID | DESCRIPTION                           |\n",
    "|:-----:|:----:|:---------------------------------------:|\n",
    "| I   | 1  | Token is inside an entity.            |\n",
    "| O   | 2  | Token is outside an entity.           |\n",
    "| B   | 3  | Token begins an entity.               |\n",
    "|     | 0  | No entity tag is set (missing value). |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "text='''We‚Äôre bringing the celebration of Syracuse University‚Äôs 150 years of impact to Chicago'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We‚Äôre bringing the celebration of Syracuse University‚Äôs 150 years of impact to Chicago\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Syracuse University, [34,53), ORG\n",
      "    Syracuse B ORG\n",
      "    University I ORG\n",
      "150 years, [56,65), DATE\n",
      "    150 B DATE\n",
      "    years I DATE\n",
      "Chicago, [79,86), GPE\n",
      "    Chicago B GPE\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(\"{}, [{},{}), {}\".format(ent.text, ent.start_char, ent.end_char, ent.label_))\n",
    "    for token in ent.as_doc():        \n",
    "        print(\"    {} {} {}\".format(token, token.ent_iob_, token.ent_type_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __text__ gives the Unicode text representation of the entity.\n",
    "- __start_char__ denotes the character offset for the start of the entity.\n",
    "- __nd_char__ denotes the character offset for the end of the entity.\n",
    "- __label___ gives the label of the entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">We‚Äôre bringing the celebration of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Syracuse University\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "‚Äôs \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    150 years\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " of impact to \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Chicago\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependency Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"The quick brown fox jumps over the lazy dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The/DT <--det-- jumps/NNS\n",
      "quick/JJ <--amod-- jumps/NNS\n",
      "brown/JJ <--amod-- jumps/NNS\n",
      "fox/NN <--compound-- jumps/NNS\n",
      "jumps/NNS <--ROOT-- jumps/NNS\n",
      "over/IN <--prep-- jumps/NNS\n",
      "the/DT <--det-- dog/NN\n",
      "lazy/JJ <--amod-- dog/NN\n",
      "dog/NN <--pobj-- over/IN\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(\"{0}/{1} <--{2}-- {3}/{4}\".format(\n",
    "        token.text, token.tag_, token.dep_, token.head.text, token.head.tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"0418539aec32498896d8cf84ca88c0e0-0\" class=\"displacy\" width=\"860\" height=\"317.0\" direction=\"ltr\" style=\"max-width: none; height: 317.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">quick</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">brown</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">fox</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">jumps</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">over</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">lazy</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">dog</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0418539aec32498896d8cf84ca88c0e0-0-0\" stroke-width=\"2px\" d=\"M70,182.0 C70,2.0 410.0,2.0 410.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0418539aec32498896d8cf84ca88c0e0-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,184.0 L62,172.0 78,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0418539aec32498896d8cf84ca88c0e0-0-1\" stroke-width=\"2px\" d=\"M160,182.0 C160,47.0 405.0,47.0 405.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0418539aec32498896d8cf84ca88c0e0-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M160,184.0 L152,172.0 168,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0418539aec32498896d8cf84ca88c0e0-0-2\" stroke-width=\"2px\" d=\"M250,182.0 C250,92.0 400.0,92.0 400.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0418539aec32498896d8cf84ca88c0e0-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M250,184.0 L242,172.0 258,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0418539aec32498896d8cf84ca88c0e0-0-3\" stroke-width=\"2px\" d=\"M340,182.0 C340,137.0 395.0,137.0 395.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0418539aec32498896d8cf84ca88c0e0-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M340,184.0 L332,172.0 348,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0418539aec32498896d8cf84ca88c0e0-0-4\" stroke-width=\"2px\" d=\"M430,182.0 C430,137.0 485.0,137.0 485.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0418539aec32498896d8cf84ca88c0e0-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M485.0,184.0 L493.0,172.0 477.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0418539aec32498896d8cf84ca88c0e0-0-5\" stroke-width=\"2px\" d=\"M610,182.0 C610,92.0 760.0,92.0 760.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0418539aec32498896d8cf84ca88c0e0-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M610,184.0 L602,172.0 618,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0418539aec32498896d8cf84ca88c0e0-0-6\" stroke-width=\"2px\" d=\"M700,182.0 C700,137.0 755.0,137.0 755.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0418539aec32498896d8cf84ca88c0e0-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M700,184.0 L692,172.0 708,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0418539aec32498896d8cf84ca88c0e0-0-7\" stroke-width=\"2px\" d=\"M520,182.0 C520,47.0 765.0,47.0 765.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0418539aec32498896d8cf84ca88c0e0-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M765.0,184.0 L773.0,172.0 757.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 90})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_lg = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple = nlp_lg.vocab[\"apple\"]\n",
    "banana = nlp_lg.vocab[\"banana\"]\n",
    "car = nlp_lg.vocab[\"car\"]\n",
    "apple_banana_sim = apple.similarity(banana)\n",
    "banana_apple_sim = banana.similarity(apple)\n",
    "apple_car_sim = apple.similarity(car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5831844"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_banana_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5831844"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banana_apple_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21747091"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_car_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def cosine(x,y):\n",
    "    return np.dot(x,y) / (np.sqrt(np.dot(x,x)) * np.sqrt(np.dot(y,y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "man = nlp_lg.vocab[\"man\"].vector\n",
    "woman = nlp_lg.vocab[\"woman\"].vector\n",
    "king = nlp_lg.vocab[\"king\"].vector\n",
    "queen = nlp_lg.vocab[\"queen\"].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7880845"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine(king-man+woman,queen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, Token.vector returns the vector for its underlying Lexeme, while Doc.vector and Span.vector return an average of the vectors of their tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp_lg(\"The quick brown fox jumps over the lazy dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp_lg(\"The lazy dog jumps over the quick brown fox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1.similarity(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999448211677"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1.similarity(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1_vec=doc1.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2_vec=doc2.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine(doc2_vec,doc1_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine(doc2_vec,doc1_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(\"I like snow\")\n",
    "doc4 = nlp(\"I hate snow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85214496"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine(doc3.vector,doc4.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
